bash\_intro
===========

date

:   2015-4-5 16:31

tags

:   bash, Analysis

category

:   bash

slug

:   bash\_intro

summary

:   How to work with bash

How to work in Unix Bash
------------------------

  -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  Imagine you have 10 files with two columns of data in each file. You want to load them and take an average of all second columns. Sounds like an easy Excell program. But it is not. When you have not 10 but 10 000 files, it will take ages for Excell to load them, also Excell is not free and is not installed everywhere. Fortunatelly there is an amazing tool that you may use : Bash shell. It is available by default in Linux/Mac OS , it can be installed via CygWin on Windows machine. It takes a couple of hours to learn, couple of days/weeks to master, and it will save you couple of years in future. Interested? So lets get started …
  Plan:
  \* What we need to know
  \* Elementary operations
  \* Secrets of mastering bash
  \* Useful links
  \* Here is how the linux console looks on Ubuntu 14.04
  Elementary Introduction
  =======================
  -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

In a nutshell we see computer memmory as a bunch of files and folders.
When we use computer in our daily routine we navigate between different
files and folders. Even when we surf the web we navigate between
webpages which are the files on remote servers. So the most “intersting”
command would be ls

1.  List all files and folders

``` {.sourceCode .bash}
$ ls
empty_file1  empty_folder1
Here empty_folder1 is a directory, and empty_file1 is a text file.
```

2.  Navigate to directory

``` {.sourceCode .bash}
$ cd empty_folder1
Now we are in empty_folder1 directory. To test that we use
```

3.  Show current directory

``` {.sourceCode .bash}
$ pwd
/home/vasiliy/tests
```

To navigate back in the parent directory we use cd .. Now lets use this
4 commands together

``` {.sourceCode .bash}
vasiliy@vasiliy-office:~/tests/empty_folder1$ pwd
/home/vasiliy/tests/empty_folder1
vasiliy@vasiliy-office:~/tests/empty_folder1$ cd ..
vasiliy@vasiliy-office:~/tests$ pwd
/home/vasiliy/tests
vasiliy@vasiliy-office:~/tests$ ls
empty_file1  empty_folder1
vasiliy@vasiliy-office:~/tests$ cd empty_folder1/
```

To create a file we may use any text editor we like. I myself am a big
fan of Sublime-Text.. To copy file `file1` to `file2` we use cp `file1`
`file2` command. To remove files we use rm filename command. To create
an empty directory we use mkdir mynewcooldirectory.

4.  Creating/Copying/Removing files

``` {.sourceCode .bash}
$ ls
$ subl empty_file2 # edit file and save it
$ ls
empty_file2
$ cp empty_file2 empty_file2_copy
$ ls
empty_file2 empty_file2_copy
$ rm empty_file2_copy #delete the copy file
$ ls
empty_file2
```

If we want to rename file, we could copy it and consequently remove it,
or use a move mv `file1` `file2` command which combines this procedures.

### Must-know commands

  -----------------------------------------------------------------
  So here is a little cheat sheet of required operations:

  1\. LiSt files and folders ls

  2\. Current directory pwd

  3\. Navigate to directory(ChangeDirectory) cd foldername, cd ..

  4\. CoPy/MoVe/ReMove files `cp file1 file2`, `mv file1 file2`,
  `rm file1`.

  A Project

  =========
  -----------------------------------------------------------------

Problem:

Create a binary bash script(a file that can be executed by linux shell)
that:

1.  lists all files in the directory
2.  creates a set of files file1, file2, file3, … file10
3.  copies file1 to file1\_copy, list all files
4.  removes file1, list all files
5.  removes all files in the directory

Additional information:

The files on computer are of two types human-readable - ASCII, and
computer readable - binary. We (humans:)) can’t understand computer code
because it is all 1s and 0s, at the same time computers can’t understand
ASCII files unless we explain them how to transfer ASCII files into
binary ones. To simplify the procedure of running the program we can
tell our system that this program is a bash program this is being done
by : `#!/bin/bash`. Then tell the system that we may run this as an
executable we do `chmod +x bashscript.sh` To create dummy empty file one
may use touch `file1` command. To delete all files in the directory we
use `*` wildcard so to delete all files it will be `rm *.` But we need
to be very careful because it will delete all files in directory, so
make sure that they match the pattern that you are using to delete
files.

algorithm:

1.  list all files in the directory ls
2.  create a list with for command
3.  `cp file1 file1_copy`, `ls`
4.  `rm file1`, `ls`
5.  delete all files in the directory `rm *`

Solution:

``` {.sourceCode .bash}
#!/bin/bash
echo "listing the files in the directory" # use echo command to print information in the terminal
ls
echo "starting the loop"
for (( i = 1; i <= 10; i++ )); do
    echo "doing loop on iteration # = $i"
    touch file$i
done
echo "done with the loop"
ls
echo "copy ``file1`` in file1_copy"
cp file1 file1_copy
ls
echo "remove file1"
rm file1
ls
```

OUTPUT:

``` {.sourceCode .bash}
$~/tests$ bash simple_prog.sh
listing the files in the directory
simple_prog.sh
starting the loop
doing loop on iteration # = 1
doing loop on iteration # = 2
doing loop on iteration # = 3
doing loop on iteration # = 4
doing loop on iteration # = 5
doing loop on iteration # = 6
doing loop on iteration # = 7
doing loop on iteration # = 8
doing loop on iteration # = 9
doing loop on iteration # = 10
done with the loop
file1  file10  file2  file3  file4  file5  file6  file7  file8  file9  simple_prog.sh
copy file1 in file1_copy
file1  file10  file1_copy  file2  file3  file4  file5  file6  file7  file8  file9  simple_prog.sh
remove file1
file10  file1_copy  file2  file3  file4  file5  file6  file7  file8  file9  simple_prog.sh
```

If we change the mode to executable `chmod +x simple_prog.sh`, then we
may run the program the following way `./simple_prog.sh`

Secrets of mastering Bash

There is only one secret of becoming good with bash - practice, you may
need to spend a little bit of energy now, but it will save you tons of
time in the future.

Useful links

Create\_melt
============

date

:   2015-4-5 17:03

tags

:   Lammps, Simulation

category

:   Lammps

slug

:   create\_melt

summary

:   How to create a polymer melt?

How to create a data file of a polymer system for Lammps.

Creating data files for polymer systems appears to be a daunting task.
The process of creating a data file includes three stages. One of
possible ways of tackling this problem would be:

1.  Create initial configuration using Monte-Carlo random walk
2.  Run a Lammps simulation for equilibrating melt
3.  Analyze chain confirmation, if not satisfactory go to stage 2.

Creating initial configuration is relatively easy. The Lammps package
comes with an tool called chain.f. Very fast Fortran program for
creating initial configurations.

To create a melt we need to create a file def.chain, which is located in
the tools/ directory.

def.chain:

``` {.sourceCode .perl}
Polymer chain definition

0.8442          rhostar
592984          random # seed (8 digits or less)
1               # of sets of chains (blank line + 6 values for each set)
0               molecule tag rule: 0 = by mol, 1 = from 1 end, 2 = from 2 ends

320             number of chains
100             monomers/chain
1               type of monomers (for output into LAMMPS file)
1               type of bonds (for output into LAMMPS file)
0.97            distance between monomers (in reduced units)
1.02            no distance less than this from site i-1 to i+1 (reduced unit)
```

After compiling \`chain.f\`:

``` {.sourceCode .bash}
gfortran chain.f -o chain.out
```

We may create a polymer melt using this command:

``` {.sourceCode .bash}
./chain.out < def.chain > init.data
```

Now the init.data looks like:

``` {.sourceCode .perl}
LAMMPS FENE chain data file

   140  atoms
   134  bonds
   0  angles
   0  dihedrals
   0  impropers
...
```

Equilibrate\_melt
=================

date

:   2015-4-5 16:57

tags

:   Lammps, Equilibration, Simulation

category

:   Lammps

slug

:   equilibrate\_melt

summary

:   How to equilibrate a polymer melt?

Introduction to polymer physics
-------------------------------

The simplest model to describe polymer chains is the Freely Jointed
Chain (FJC) model [FJC]\_. In this simple model ([randomcoil]\_) a
polymer chain is represented as a succession of monomer units that
interact \$textbf{only}\$ by covalent binding forces, therefore the
potential energy of the polymer is taken to be independent of its shape.
Therefore at thermodynamic equilibrium, all of its shape configurations
are equally likely to occur as the polymer fluctuates in time, according
to the Boltzmann distribution. As a result, the bond length is fixed,
and the internal rotations are completely free [equilibrating]\_

Polymer configuration can be described by setting up the positions of
each monomer: for example \$3N\$ Cartesian coordinates \$XYZ\$ with
respect to the laboratory fixed frame. Since all of the configurations
are random, the end-to-end vector, connecting the first and the last
units of a chain, should have a zero average [average]\_ and a certain
variance.

\$\$\\mathbf{R}(N)=\\sum\_{i=1}\^{i=N}\\mathbf{r}\_i\$\$

Evidently [central\_limit]\_, a long freely jointed chain will obey
Gaussian statistics: the probability to observe a certain end-to-end
vector \$\\mathbf{R}\$ is given by the Gaussian distribution function
with zero average (centered at the origin) and mean squared value.

\$\$\\Big \\langle \\mathbf{R}(N) \\Big \\rangle = 0\$\$

\$\$\\Big \\langle \\mathbf{R\^2}(N)\\Big \\rangle \\equiv \\Big
\\langle R\^2(N)\\Big \\rangle = Nb\^2\$\$ where \$b\$ is the bond
length and \$N\$ is the number of bonds. Another value used in polymer
physics is the radius of gyration \$R\_g\$ which is defined by the:

\$\$R\^2\_g(N) = \\frac{1}{N}
\\Sigma\_{i}(\\mathbf{r}\_i-\\mathbf{r}\_{CM})\^2\$\$

where \$\\mathbf{r\_i}\$ \\- is the position vector of bead number \$i\$
in the chain and \$r\_{CM}\$ is the position vector of the center of
mass of the polymer chain. Schematically it is represented in
[figPolymerParameters]\_. For ideal chains\\index{ideal chains}, the
radius of gyration (see [figPolymerParameters]\_) can also be calculated
by:

\$\$\<R\^2\_g(N)\> = \\frac{\<R\^2(N)\>}{6}\$\$

Despite its simplicity, \$\<R\^2\_g(N)\> = \\frac{\<R\^2(N)\>}{6}\$ is
among the most fundamental results of polymer science - it provides an
estimate of the length scales in polymer melts, as well as serving as a
bridge to connect experimental results to MD.

![](../images/end_to_end_explained.png)

FIG. [figPolymerParameters]\_ Schematic representation of a polymer
chain. Two main characteristic values are shown: the end-to-end distance
which corresponds to the vector connecting the first and the last beads
of the polymer, and the gyration radius which is a characteristic
average size of the polymer chain.

In practice, chains are non-ideal, they interact and have internal
stiffness. Moreover, since the number of beads \$N\$ is usually a large
number, no distinction is made between the finite and the infinite
number of bonds. In 1969 Flory used these ideas to define the
characteristic ratio \$C\_{\\infty}\$ of a polymer as:

\$\$C\_{\\infty} = \\lim\_{N\\to\\infty} \\frac{\<R\^2(N)\>}{Nb\^2}\$\$

By definition, \$C\^{FJC}\_{\\infty} = 1\$. Values of \$C\_{\\infty}\$
larger than \$1\$ occur when some of the degrees of freedom are
constrained. The \$C\_{\\infty}\$ can be used as a measure of stiffness
along the polymer backbone. The value \$C\_{\\infty}\$ is experimentally
observable therefore one can judge the level of equilibration of polymer
melts by how well their Mean Square Internal Distances(\$R\^2(n)/n\$)
plot saturate on the value \$\<R\^2(n \\to \\infty)\> \\to C\_{\\infty}
Nb\^2\$, explained in [figMSID]\_.

![](../images/msid_explained.png)

FIG. [figMSID]\_ Schematic representation of evolution of Mean Square
Internal Distances (MSID) for equilibrated and non-equilibrated polymer
melts. Upon equilibration chain MSID saturates on correct End-to-End
distances that can be directly obtained from number of units in the
chain, bond length and chain stiffness

Theoretical aspects of polymer melt equilibration in MD
-------------------------------------------------------

The MD scheme takes care of the time evolution of the model used to
study a particular system. Still, the first configuration (meaning
positions and velocities (for all particles) have to be defined. For the
case of short inorganic molecules, the initial positions can be set up
”by hand” on the vertices of a perfect crystal. This is not the case for
the long chain high-temperature polymer melt. Therefore, one needs to
start with a configuration that closely resembles an equilibrated,
disordered and amorphous system. This can be achieved using a
Monte-Carlo algorithm that will efficiently decorrelate an artificial
configuration so as to let it acquire equilibrium properties. For
instance, in the present work melts were created using self-avoiding
random walk via a chain.f tool provided by the LAMMPS Molecular Dynamics
Simulator ([lammps]\_) package.

After initial configurations are created, polymer chains need to be
equilibrated. Unlike short molecules, long chain polymers require both
thermodynamic and configurational equilibration. Configurational
equilibration can be achieved when the Mean Square Internal Distance
(\$MSID\$) parameter is equilibrated and correspond to pseudo-Gaussian
chain, see FIG.[figmsid]\_. This was done via Kremer-Grest equilibration
process 7 using bead-springs polymer representation ([sliozberg]\_ )The
method used for configurational equilibration is a fast ’Dpd-push-off’ -
it is a commonly used way to prepare well-equilibrated melts. This
method is an extension of the slow push-off method developed by Auhl et
al. ([auhl]\_). The idea of application of soft repulsive potentials for
equilibration of polymer melts is effective provided the potential is
applied to the initial configurations that closely match equilibrium
structures at large length scales. The details and the practical aspects
of the algorithm will be discussed below. The MSID plots, alongside
plots of the thermodynamic parameters evolution provide evidence on a
fine quality of equilibration achieved using the procedure explained
above.

![](../images/output_20_1.png)

Mean Square Internal Distance Plot (\$MSID\$). The plot indicates well
equilibrated character of polymer melt. Linear growth at the initial
stages is followed by saturation on the

Practical aspects of polymer equilibration
------------------------------------------

We have already discussed the theoretical aspects of polymer
equilibration. We emphasized the importance of creating decorrelated
initial configurtions and tracking the evolution of MSID parameter as a
gauge of equilibration. In this subsection we will discussed the
practical aspects of polymer equilibration.

Now it's time to "make hands dirty" and cover the steps and code used
for equilibration.

> a.  We start with unphysical Kremer-Grest equilibration using
>     bead-spring model. (no angles in the atom topology only
>     atoms+bonds)
> b.  We add the angle/dihedral parts
> c.  Finish up via physical NVE+NPT run

Below is my LAMMPS code I used for the Kremer-Grest equilibration.
Details may be found in papers of [sliozberg]\_ or [auhl]\_. This is the
main part of the equilibration, after this step we expect the chains to
be fully relaxed and have Gaussian chain statistics.

``` {.sourceCode .perl}
# Kremer-Grest model.

units lj
atom_style bond
special_bonds lj/coul 0 1 1
read_data init.data
neighbor 0.4 bin
neigh_modify every 1 delay 1
comm_modify vel yes
bond_style fene
bond_coeff * 30.0 1.5 1.0 1.0
dump            mydump all dcd 50000 equil.dcd
timestep 0.01
thermo 100
thermo_modify norm no
pair_style dpd 1.0 1.0 122347   # very soft pair-potential
pair_coeff * * 25 4.5 1.0

velocity all create 1.0 17786140

# bonds in init.data are unphysicaly close
# fix nve/limit doesn't let the system to explode
# during the equilibration run

fix 1 all nve/limit 0.001
run 500
fix 1 all nve/limit 0.05
run 500
fix 1 all nve/limit 0.1
run 500
unfix 1
fix 1 all nve
run 50000

write_data tmp.restart_dpd.data

pair_coeff * * 50.0 4.5 1.0
velocity all create 1.0 15086120
run 50
pair_coeff * * 100.0 4.5 1.0
velocity all create 1.0 15786120
run 50
#......
run 100
pair_coeff * * 1000.0 4.5 1.0
velocity all create 1.0 15086189
run 100
write_data tmp.restart_dpd1.data

pair_style hybrid/overlay lj/cut 1.122462 dpd/tstat 1.0 1.0 1.122462 122347
pair_modify shift yes
pair_coeff * * lj/cut 1.0 1.0 1.122462
pair_coeff * * dpd/tstat 4.5 1.122462
velocity all create 1.0 1508612013   # this velocity reset is repeated 10 times
run 50
write_data tmp.restart_push.data
velocity all create 1.0 15086125
run 2000000

write_data equil.data
```

The init.data that was created using self-avoiding random walk and
imported at the beginning of the script above didn't have any angle
sections. But the actual simulation that we will run will need this
parameters. So here I present a short SED/AWK script to update the data
file. Interested read may find a good Introductory tutorial on
<https://quickleft.com/blog/command-line-tutorials-sed-awk/>.

``` {.sourceCode .perl}
LAMMPS FENE chain data file

   140  atoms
   134  bonds
   0  angles
   0  dihedrals
   0  impropers
...
```

So the data file didn't have any information about angle, dihedrals in
the systems. Lets now consider possible ways of tackling this problem.

``` {.sourceCode .perl}
#!/bin/bash


# here is the main file for creating a polymer melt
# input : DATA_file_input = initial melt created by chain.f, or the equil.data - equilibrated melt by in.kremer that has only fene Bonds
# output : DATA_file_output = final melt that has angles ( if required dihedrals as well)

#set input and output
datain="equil.data"
dataout="tmp.data"
#get information about number of atoms and number of bonds
STR=$(less $datain | grep atoms)
LIT=$(echo $STR | grep -o [0-9]*)
natoms=$LIT
# calculate number of angles, knowing how many atoms and bonds we have
STRb=$(less $datain | grep bonds)
LITb=$(echo $STRb | grep -o [0-9]*)
nbond=$LITb

let nangle=(2*$nbond-$natoms)
let ndih=0

#write data file in required format
cp $datain  2.info

echo "LAMMPS  data file

$natoms  atoms
$nbond  bonds
$nangle  angles

1  atom types
1  bond types
1  angle types
" > 1.info

sed -i '1,/bond types/d' 2.info
sed -i '1d' 2.info
sed -i '/Velocities/,/Bonds/{//!d}' 2.info
sed -i '/Velocities/d' 2.info

cat *.info > temprary_file
rm *.info

#creating additional files for generating angle bond topology
echo "1  * * *   * * " > angles_by_type.txt

# sed -i '/improper/d' result_without.data
bash gen_all_angles_topo.sh temprary_file  $dataout
rm temprary_file
rm angles_by_type.txt

#replace multiple blanc lines with a single one
sed -i '/^$/N;/^\n$/D' $dataout

sed -i '/dihedral/d' $dataout

sed -i '/improper/d' $dataout

sed -i '/Bond Coeffs/,/Atoms/{//!d}'  $dataout
sed -i '/Bond Coeffs/d'  $dataout
```

After applying this script we get the following data file:

``` {.sourceCode .perl}
LAMMPS  data file

140  atoms
134  bonds
128  angles

1  atom types
1  bond types
1  angle types
...
```

Introduction
============

date

:   2015-4-5 15:08

tags

:   About

category

:   About

slug

:   introduction

summary

:   Why do I write this blog?

sidebarimage

:   images/background/s.jpg

About me
--------

  --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

  .. .. figure:: \~/blog/images/me.jpg

  .. :height: 100px

  .. :width: 100 px

  .. :scale: 400 %

  .. :alt: alternate text

  .. :align: center

  .. Its me

  Hi, my name is Vasilii Triandafilidi.

  I am a first year PhD student at the University of British Columbia.

  I work under supervision of Prof. Savvas Hatzikiriakos' lab [lab]\_ and Prof. Rottler [Prof\_Rottler]\_ .

  In the past I had a pleasure working in the Prof. Norman's group [Prof\_Norman]\_ under supervision of Dr. Stegailov.

  In my research I focus on investigating properties of matter using Method of Molecular Dynamics.

  Molecular Dynamics [md]\_ is a computational tool

  that treats matter as a system of interacting particles.

  .. \_figmd:

  .. figure:: ../images/md\_explained.png

  :width: 550pt

  :alt: lala

  :align: center

  Schematic representation of Molecular Dynamics flow

  In order to run a Molecular Dynamics Simulation one needs to provide the initial atomic positions \$\\mathbf{r\_1},\\mathbf{r\_2} ... \\mathbf{r\_N}\$, the inter-atomic potential \$U(\\mathbf{r})\$ and a set of constraints also known as an ensemble for integrating the equations of motion. Then

  using this information of the atomic positions, and interacting potential; the Newtons equations of motion are used to calculate the atomic positions on the next time step.

  After simulation is terminated one obtains the final positions

  \$\\mathbf{r\^{'}\_1},\\mathbf{r\^{'}\_2} ...\\mathbf{r\^{'}\_N}\$. The macroscopic parameters can be calculated by integrating and averaging, e.g temperature can be calculated as a mean square

  kinetic energy, i.e velocity of the system.

  In particular I am very interested in investigating the process of polymer crystallization.

  .. \_figspagetti:

  .. figure:: ../images/spagetti.png

  :width: 300pt

  :align: center

  Spaghetti representation of polymer chains

  .. \_figbidisp:

  .. figure:: ../images/bidisp\_equal1.png

  :width: 200pt

  :alt: lala

  :align: center

  Bundle like crystallite upon bidisperse polymer crystallization. Short chains are colored in red, long chains in green

  Tools:

  ------

  To do Molecular Dynamics simulation I use open source code [lammps]\_ , to analyze trajectories I use a powerful Python

  based package [mdanalysis]\_ , to vizualize my results I use [vmd]\_ .

  .. .. figure:: \~/blog/images/md.png

  .. :height: 100px

  .. :width: 100 px

  .. :scale: 400 %

  .. :alt: alternate text

  .. :align: center

  Molecular Dynamics

  So why do I write this blog?

  ----------------------------

  --

  I write this blog mostly because I want to keep track of my progress.

  I do also believe in an open-source and reproducible science. I am very against inventing bicycles over and over again. The best way to avoid it is to share, to talk to people and hear their feedback.

  I chose Python language because of its open-source nature and great package infrastructure. If you have a cool program you load it, and other person can install it as easy as

  .. code-block:: bash

  pip install packagename

  I think scientific community (especially those who work in simulation) have to learn a lot from this approach. Those who got interested in open-source science may address a great project by Mozilla [mozillascience]\_. Besides,Python is a beautiful and powerful language. The range of its capabilities varies from building a static blog [pelican]\_ to solving a numerical equations. If you haven't used it yet, I think, you should give it a try.

  I spend a lot of time working on my project and I hope the stuff that I am doing maybe useful for other people as well.

  Contact information:

  --------------------

  email: vasiliy(dot)triandafilidi( at )gmail.com

  .. [pelican] Pelican: <http://docs.getpelican.com/en/latest/index.html>

  .. [lab] Prof. Savvas Hatzikiriakos: <http://www.chml.ubc.ca/faculty-staff/hatzikiriakos.php>

  .. [md] Method of Molecular Dynamics: <http://en.wikipedia.org/wiki/Molecular_dynamics>.

  .. [vmd] VMD: <http://www.ks.uiuc.edu/Research/vmd/>

  .. [mdanalysis] MDanalysis: <https://code.google.com/p/mdanalysis/>

  .. [lammps] Lammps www.lammps.sandia.gov

  .. [Prof\_Rottler] <http://www.phas.ubc.ca/~jrottler/index.html>

  .. [Prof\_Norman] <http://www.ihed.ras.ru/norman/en/index.php>

  .. [mozillascience] Mozilla Science: <https://www.mozillascience.org/>

  Lammps\_intro

  \#\#\#\#\#\#\#\#\#\#\#\#

  :date: 2015-4-5 16:54

  :tags: Lammps, Simulation

  :category: Lammps

  :slug: lammps\_intro

  :summary: How to run a simples simulation in Lammps

  Running simulations in Lammps. In this section we will create a group of atoms

  and run an easy lammps simulation with lj potential.

  .. code-block:: perl

  \# 3d Lennard-Jones melt

  units real

  \#Angstroms, T kelvins,

  .. code-block:: perl

  source

  boundary p p p

  \#periodic boundary conds

  atom\_style atomic

  lattice bcc 3.82

  \#10 times x , 10 times y , 10 times z \#size

  region box block 0 10 0 10 0 10

  create\_box 1 box

  create\_atoms 1 box

  mass 1 20.0

  Specifying pair potential that we are using:

  .. code-block:: perl

  \#potential

  pair\_style lj/cut 10.5

  pair\_coeff 1 1 0.11 4.11 10.5

  .. code-block:: perl

  \#assigning random velocties to diffrent atoms

  velocity all create 273.3 50007878

  neighbor 0.3 bin

  neigh\_modify every 20 delay 0 check no

  \#how often we want to dump thermodynamic output

  thermo 100

  \#how often we want to dump coordinates

  dump 1 all cfg 50 dump.\*.cfg mass type xs ys zs

  Specifying what type of `fix` we are using:

  .. code-block:: perl

  fix 1 all nve

  run 1000

  write\_data result.data

  How to run a simulation from a saved data file as initial coordinates input file, and dump trajectory for further visualization

  .. code-block:: perl

  \#LAMMPS

  units real

  boundary p p p

  atom\_style atomic

  pair\_style lj/cut 10.5

  \# use this pair style , ljcut means that we have 12/6 potential Van-der-Vaals, and 10.5 is its cutoff

  read\_data result.data \# read data from a saved state

  pair\_coeff 1 1 0.11 4.11 10.5 \# read parameters

  \#set particles velocity to 0 C

  velocity all create 273.3 50007878

  \# list thermodynamic output every 100 steps

  thermo 100

  \# dump images that would be visualized by the AtomEye program

  \# They all have cfg format

  \# 1 is a name of our dump

  \# all - is that we dump all atoms

  \# cfg is format

  \# 50 - is how often we dumping

  \# name.*.cfg , where* means that when we dump these files they are going to be saved in this format

  \# step=0 myrun.0.cfg, step=50 myrun.50.cfg and etc

  \# we are dumping mass, type of the particles and x , y , z coordinates

  dump 1 all cfg 50 myrun.\*.cfg mass type xs ys zs

  \#use this fix file

  fix 1 all nve

  \#run for these many steps

  run 2000

  \#write output into result2.data (if we want to simulate it later)

  write\_data result2.data

  \# initial - \> result.data -\> result2.data

  installing\_soft

  \#\#\#\#\#\#\#\#\#\#\#\#\#\#\#

  :date: 2015-4-8 13:54

  :tags: Lammps, VMD, MDAnalysis, Software, Python

  :category: Software

  :slug: installing\_soft

  :summary: Molecular Dynamics lunch box. How to install software on your machine?

  What do we need?

  ----------------

  --

  In order to do Molecular Dynamics one needs to install essential software.

  We'll need to install several packages in order to be fully ready for our simulations:

  1\. Molecular Dynamics package [lammps]\_

  2\. Python installation with all essential packages [anaconda]\_

  3\. Molecular Trajectory Analysis package [mdanalysis]\_ , [pizza]\_ ,
  [moltemplate]\_

  4\. Tool to visualize your trajectory [vmd]\_

  How to install Lammps?

  ----------------------

  --

  To install Lammps one may follow one of these [tutorials](http://lammps.sandia.gov/doc/Section_start.html#start_2_5)

  The easiest way to install [lammps]\_ on Ubuntu machines would be :

  .. code-block:: bash

  sudo add-apt-repository ppa:gladky-anton/lammps

  sudo apt-get update

  sudo apt-get install lammps-daily

  \#it builds with FFTW3 and OpenMPI.

  lammps-daily -in in.lj

  \#To get a copy of the current documentation and examples:

  \#which will download the doc files in /usr/share/doc/lammps-daily-doc/doc and example problems in /usr/share/doc/lammps-doc/examples.

  sudo apt-get install lammps-daily-doc

  On my mac it was very straight-forward as well:

  .. code-block:: bash

  brew tap homebrew/science

  brew install lammps

  \#brew install lammps --HEAD --with-mpi

  On Windows one may download a setup file and install it, or install it using [lammps\_cygwin](http://sjbyrnes.com/LAMMPStutorial.html)

  How to install Anaconda Python distribution?

  --------------------------------------------

  I love Python, i think it is arguably the easiest "heavyweight" programming language to learn, it has enormous potential for your tasks, and a wonderful community.

  For scientific use one may download an open-source distribution called Anaconda which has everything a scientist may need.

  On any \*nix machine one may install it by downloading .sh file, and running bash Anaconda\*.sh

  Installing any other Python packages will be as easy as: pip install \<name of the package\>

  So to install Molecular Dynamics trajectory Analysis program one can install [mdanalysis]\_, which is a Python based program, with an easy interface and good community.

  To install it one simply needs to:

  .. code-block:: bash

  pip install MDAnalysis

  To install [pizza]\_ and [moltemplate]\_ one simply needs to download the .tar files, extract them and add to the path

  To do that we need to add this lines to \~/.bashrc file

  .. code-block:: bash

  export PATH="\$PATH:/path\_to\_moltempalate/moltemplate/src"

  export MOLTEMPLATE\_PATH="/path\_to\_moltempalate/moltemplate/common"

  export PYTHONPATH="\$PYTHONPATH:/path\_to\_pizza/pizza-2Jul14/src"

  Visualizing Molecular Dynamics Trajectory

  -----------------------------------------

  To visualize MD trajectories, we need to install [vmd]\_. To do that on Linux systems, we need to go to their website and download a .tar file.

  .. code-block:: bash

  tar -xzvf vmd.tar.gz

  cd vmd/

  After downloading and untaring the archive it is all gravy:

  We just need vim configure, and change home\_bin\_dir=..,\`home\_library\_dir\` to where we want VMD to be.

  On mac systems just needs to download a .dmg file and install it by just clicking it. Sometimes we also need to specify the location of the executable:

  .. code-block:: bash

  vmdappdir='/Applications/VMD 1.9.2.app/Contents'

  \# vmdappdir='/Applications/VMD1.8.5.app/Contents'

  \# (change it to where vmd lies, obviously ;))

  alias vmd='"\$vmdappdir/Resources/VMD.app/Contents/MacOS/VMD" \$\*'

  alias textvmd="vmd -dispdev text \$\*"

  .. [moltemplate] Moltemplate: <http://www.moltemplate.org/>

  .. [pizza] Pizza: <http://www.sandia.gov/~sjplimp/download.html>

  .. [vmd] Visual Molecular Dynamics: <http://www.ks.uiuc.edu/Development/Download/download.cgi?PackageName=VMD>

  .. [mdanalysis] MD: <https://code.google.com/p/mdanalysis/>

  .. [anaconda] Anaconda Python Installation: <https://store.continuum.io/cshop/anaconda/>

  .. [lammps] lammps: <http://lammps.sandia.gov/>

  MDAnalysis\_advanced

  \#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#

  :date: 2015-4-8 14:53

  :tags: mdanalysis, Python, Analysis

  :category: mdanalysis\_advanced

  :slug: mdanalysis\_advanced

  :summary: You have run a simulation, now what? How to analyze MD trajectories?

  This is a ipython notebook which demonstrates how to use MDAnalysis

  package:

  .. code-block:: python

  from MDAnalysis import \*

  import numpy as np

  %matplotlib inline

  .. code-block:: python

  u = Universe("poly.psf", "poly.pdb")

  print u

  .. parsed-literal::

  \<Universe with 12000 atoms and 11700 bonds\>

  .. code-block:: python

  u.atoms

  .. parsed-literal::

  \<AtomGroup with 12000 atoms\>

  Now we have imported a universe, which has all of our frames and

  information of our system. Accessing it becomes pretty straightforward:

  .. code-block:: python

  a = u.selectAtoms("all")

  .. code-block:: python

  a.positions

  .. parsed-literal::

  array([[-11.71399975, -8.36999989, 21.4810009 ],

  [-11.65499973, -8.65400028, 20.80699921],

  [-11.21700001, -9.38300037, 21.23900032],

  ...,

  [ 8.22000027, -6.82600021, 1.65400004],

  [ 8.67800045, -7.45300007, 1.37300003],

  [ 8.41399956, -7.28299999, 0.65499997]], dtype=float32)

  Now imagine we want to find something in our selection, lets say center

  of mass, vous a la:

  .. code-block:: python

  a.centerOfMass()

  .. parsed-literal::

  array([ 0.27253684, 1.12546084, 1.68031492])

  MDanalysis allows you to access some other fields rather than just

  atoms:

  .. code-block:: python

  a.bonds

  .. parsed-literal::

  \<TopologyGroup containing 11700 Bonds\>

  .. code-block:: python

  b1 = a.bonds.atom1.positions

  .. code-block:: python

  b2 = a.bonds.atom2.positions

  .. code-block:: python

  bonds\_vectors = (b2-b1)

  .. code-block:: python

  bonds\_vectors

  .. parsed-literal::

  array([[ 0.05900002, -0.2840004 , -0.67400169],

  [ 0.43799973, -0.72900009, 0.43200111],

  [ 0.6960001 , -0.99399948, -0.7159996 ],

  ...,

  [-0.43400002, -0.8380003 , -1.17799997],

  [ 0.45800018, -0.62699986, -0.28100002],

  [-0.26400089, 0.17000008, -0.71800005]], dtype=float32)

  This way we can write a function that takes a Universe as an input and

  produces a normalized bond\_vector list as an output:

  .. code-block:: python

  def get\_bondlist\_coords(u):

  """

  input: Universe

  output: bonds (that are in the domain, normalized)

  generate normalized coordinates of bond vectors

  get universe , return bonds(coordinates)

  generate coor of all bonds(bond = chord i-1 - i+1 ), normalize it

  """

  bonds = u.bonds.atom2.positions - u.bonds.atom1.positions

  \# angles = u.angles

  \# bonds = angles.atom3.positions - angles.atom1.positions

  \# coords = angles.atom2.positions

  norm = np.linalg.norm(bonds,axis=1)

  bonds /= norm[:, None] \#the norm vector is a (nx1) and we have to create dummy directions -\> (n,3)

  return bonds

  .. code-block:: python

  get\_bondlist\_coords(u)

  .. parsed-literal::

  array([[ 0.08040691, -0.38704386, -0.91854876],

  [ 0.45917124, -0.76423758, 0.45288265],

  [ 0.49398914, -0.70549554, -0.5081839 ],

  ...,

  [-0.28753173, -0.55518818, -0.78044319],

  [ 0.5546512 , -0.7593146 , -0.34029898],

  [-0.33688259, 0.21693134, -0.91621554]], dtype=float32)

  Interesting project:
  --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

![image](./images/output_1_0.png)

Lets calculate something more interesting, say Mean Square Internal
Difference parameter for the trajectory. Our script will be able to
consider polydisperse chains as well as monodisperse ones. Imagine we
have a polymer of the size 2N atoms per chain. So by definition :

$$R_{ij} = (r_i - r_j)$$

$$MSID = < \dfrac{R^2_{ij}(i-j)}{|i-j|} >$$

, where :

$$i = 0,..,N//2, j = N-i-1$$

averaging is being done over all chains

``` {.sourceCode .python}
import matplotlib.pyplot as plt

def max_chain(u):
    """
    input: MDAnalysis universe
    output: maximum length of all of the chains present(integer)
    """
    maxlen=0
    for res in u.residues:
        reslen=len(res)
        if maxlen<reslen:
            maxlen=reslen
    # print "maxlen = %f" % maxlen
    return  maxlen-1

def save_plot_r2n(n_array, R2_array,psffile,frame,logplot=False):
    """
    input: n_array - array of n's, R2_array - array of R_n, psffile - name of future files, frame, logplot
    saves a frame of r2_n
    """
    # plt.cla()
    plt.ylabel(r'$\mathrm{\frac{R^2(n)}{n}}$')
    if logplot==True:
        print "xlogscale"
        plt.xscale('log')
        plt.xlabel(r'$\mathrm{log(N)}$')
    else:
        print "regular xscale"
        plt.xlabel(r'$\mathrm{N}$')
    plt.title(r'$\mathrm{\frac{R^2(n)}{n} evolution, frame = %s} $' % (frame) )
    plt.plot(n_array,R2_array,'--')
    plt.show()
#     plt.savefig('R2%s_%.5d.png' % (psffile,frame))
    return None

def get_r2n(u,psffile,frame,Noff=1,logplot=False):
    """
    create a list of
    R2_array - array of distances
    n_array - array of number of bonds between atoms
    k_array - array of number of atoms with this bonds
    start looping in residues
    for every residue:
        start from the middle of it
            calculate the closest atom_i - atom_-i
            if it is the first time we have the number of bonds so big, we expand our lists by appending
            else: we just put it to the nth position
    then the last elements of the array will be deleted, since there is not enough statistics for this chains

    """
    R2_array = []
    n_array = []
    k_array = []

    for res in u.residues:
        chainlen = len(res)/2
        for i in range(chainlen)[::-1]:
            ag1, ag2 = res.atoms[i].pos, res.atoms[-i-1].pos
            tmpdiff = ag1-ag2
            r2 = np.dot(tmpdiff,tmpdiff)
            n = (chainlen-i)
            # print n

            # calc n
            if n >= len(R2_array):
                R2_array.append(r2)
                n_array.append(2*n-1)
                k_array.append(1)
            else:
                R2_array[n] += r2
                k_array[n] += 1
                n_array[n] = n*2-1

    R2_array = np.array(R2_array)
    n_array = np.array(n_array)
    k_array = np.array(k_array)
    R2_array /= k_array*n_array
    R2_array = R2_array[:-Noff]
    n_array = n_array[:-Noff]
    save_plot_r2n(n_array, R2_array,psffile,frame,logplot)

    return None

get_r2n(u,"myfile",0,Noff=1,logplot=False)
```

![image](./images/output_20_1.png)

Using\_vmd
==========

date

:   2015-4-9 16:40

tags

:   VMD, Python, Lammps, Software

category

:   VMD

slug

:   using\_vmd

summary

:   How to visualize your simulation results?

You have run your simulation. Now what?
---------------------------------------

So after you managed to get your trajectories from Lammps, or other
Simulation packages its time to create nice vizualizations. In this blog
entry I will cover how do I use VMD and Lammps together.

Making Lammps to output trajectory files
----------------------------------------

In Lammps I use this command to produce trajectory files:

``` {.sourceCode .perl}
dump            dump_traj all dcd 20000 traj.dcd
dump_modify     dump_traj sort id unwrap yes
write_data      traj.data
```

It will produce a .dcd file which will contain information about
position of atoms for each timestep. The best part about .dcd format is
that it is already binary, therefore takes about 5 times less space on
your hard drive than ASCII files. Also it can be read by almost every MD
trajectory processing software packages such as [vmd]\_ and
[mdanalysis]\_ .

Vizualizing your trajectory:
----------------------------

![image](./images/using_vmd/polymer_amor.png)

![image](./images/using_vmd/polymer100.png)

![image](./images/using_vmd/polymer_cryst.png)

To visualize your trajectory one needs to give VMD information about
bonds in the system, by providing VMD with .psf files, i.e bond
information files. Here comes handy the .data file: traj.data and
[topotools]\_ :

``` {.sourceCode .tcl}
topo readlammpsdata traj.data molecular
animate write psf traj.psf
```

And now we can use VMD to visualize the results:

``` {.sourceCode .tcl}
mol load psf traj.psf
animate read dcd traj.dcd
```

I wrote a simple python script to produce .psf file out of data file.

``` {.sourceCode .python}
#!/usr/bin/env python
import os
import argparse
def create_psf(args):
    """
    given data file produce psf file if it doesn't exist yet
    if it does then use it
    """

    if not os.path.exists(os.path.abspath(args.psffile)):
        psffile = os.path.splitext(args.psffile)[0]
        PSF = psffile+'.psf'
        DCD = os.path.splitext(args.traj)[0] + '.dcd'
        DATA = os.path.splitext(args.datafile)[0] + '.data'

        vmdscript = "create_psf.vmd"

        # write VMD loader script
        parameters = {'vmdfile': vmdscript,
                      'topology': PSF,
                      'datafile': DATA,
                      'trajectory': DCD,
                      'trajskip':args.trajskip}

        script = """\
            package require topotools
            topo readlammpsdata "{0[datafile]}" angle
            animate write psf "{0[topology]}"
        exit
        """.format(parameters)


        with open(vmdscript, 'w') as tcl:
            tcl.write(script+'\n')

        #os.system("vmd -dispdev text -e {0[vmdfile]}".format(parameters))

        print "Wrote VMD script {0}  ".format(vmdscript)
        print "If there is an error with {0}: 'source {0}' to load everything manually, then repeat ".format(vmdscript)
        print "running the python script with explicict parameters that were generated".format(vmdscript)
    else:
        print "the file %s already exists" % args.psffile


    return args

def main():
    parser = argparse.ArgumentParser(description=\_\_doc\_\_,
                                formatter_class=argparse.ArgumentDefaultsHelpFormatter)
    parser.add_argument("-f", "--psf", dest="psffile",
                     help="Name of the future files, all other files will start with FILE",
                     metavar="FILE")
    parser.add_argument("-d", "--data", dest="datafile",
                    default="./figures/polymer_0.8.data",
                    # type=lambda x: is_valid_file(parser, x),
                    help="read datafile and if exists then convert it to psf file by invoking a vmd script",
                    metavar="FILE")

    parser.add_argument("-t", "--trajectroy", dest="traj",
                        default="quenchsim.dcd",
                        help="Input trajectory file)", metavar="FILE")
    parser.add_argument("-s",  "--trajskip", dest="trajskip",
                    default=40,
                    type=int,
                    help="How many steps are to be skipped when trajectory \
                                        file is being red\
                                        (needs to be > 1, < number of frames) \
                                        type (default: %(default)s)")
    parser.add_argument("-e", "--endframe", dest="endframe",
                    default=-1,
                    type=int,
                    help="End frame of the trajectory file type (default: %(default)s)")
    parser.add_argument("-st",
                    "--startframe",
                    dest="startframe",
                    default=0,
                    type=int,
                    help="Start frame of the trajectory file type (default: %(default)s)")

    args = parser.parse_args()
    args = create_psf(args)
    return None

if __name__ == '__main__':
    main()
```

Just run this commands to run the script:

``` {.sourceCode .bash}
$python test.py -h
usage: test.py [-h] [-f FILE] [-d FILE] [-t FILE] [-s TRAJSKIP] [-e ENDFRAME]
               [-st STARTFRAME]
optional arguments:
  -h, --help            show this help message and exit
  -f FILE, --psf FILE   Name of the future files, all other files will start
                        with FILE (default: None)
  -d FILE, --data FILE  read datafile and if exists then convert it to psf
                        file by invoking a vmd script (default:
                        ./figures/polymer_0.8.data)
  -t FILE, --trajectroy FILE
                        Input trajectory file) (default: quenchsim.dcd)
  -s TRAJSKIP, --trajskip TRAJSKIP
                        How many steps are to be skipped when trajectory file
                        is being red (needs to be > 1, < number of frames)
                        type (default: 40)
  -e ENDFRAME, --endframe ENDFRAME
                        End frame of the trajectory file type (default: -1)
  -st STARTFRAME, --startframe STARTFRAME
                        Start frame of the trajectory file type (default: 0)
```

Calculate Persistence Length
============================

date

:   2015-4-13 15:23

tags

:   MDAnalysis, Python, Analysis

category

:   MDAnalysis

slug

:   calculate-persistance-length

summary

:   How to calculate persistance length via Bond Correlation Function?

What do we want to calculate?
-----------------------------

Bond correlation function:

$$C(i) = < u_0(t) u_i(t) >$$

average by time, by residues

This function shows correlation between the first segment in the chain
and the rest of the chain. After averaging by time and residues we will
be able to obtain such parameters as persistance length and etc. At
first the correlation will decay exponentially, i.e in y-log scale it
will be linear. Then the x-coordinate of the point when the behaviour
will stop being exponential(linear in ylog scale) will correpospond to
the persistence length(of course we need to multiply n by \$l\_0\$ which
is the bond length). Calculation:

![image](./images/output_1_0.png)

Algorithm:
----------

``` {.sourceCode .python}
import numpy as np
from MDAnalysis import *
from read_parameters import read_traj_vmd
import os
import matplotlib.pyplot as plt
from pylab import polyfit
from IPython.display import Image
```

1.  Get bonds vectors
2.  Calculate Bond Correlation Function
3.  Plot the results
4.  Do linear fitting of the first few points and extrapolate the linear
    plot
5.  Find the linear curve will start being different than our plot -\>
    it will be the persistance length.

``` {.sourceCode .python}
def get_bondlist_coords(u):
    """
    input: Universe
    output: bonds (that are in the domain, normalized)
    generate normalized coordinates of bond vectors
    get universe , return bonds(coordinates)
    generate coor of all bonds(bond = chord i-1 - i+1 ), normalize it
    """
    bonds = u.bonds.atom2.positions - u.bonds.atom1.positions
    bonds /= np.sqrt((bonds*bonds).sum(axis=1))[:,None]
    return bonds
```

``` {.sourceCode .python}
def save_plot_bondacf(n_array, C_array,name):
    """
    saves a frame of C(n) BondACF
    """
    plt.ylabel(r'$\mathrm{C(n) = <u_0(t) u_n(t)}$')
    plt.xlabel(r'$\mathrm{log(n)}$')
    plt.grid(True)
    plt.yscale('log')
    plt.ylim(-0.1,1.1)
    plt.title(r'$\mathrm{%s\ C(n) = <u_0 u_n >} } $' % ( name) )

    #fitting the first part, experimental
    xfirst = n_array[:10]
    m,b = polyfit(xfirst,np.log(C_array[:10]),1)

#     plt.plot(n_array,C_array,'go',,'r-')
    plt.plot(n_array,np.exp(m*n_array+b),'r-')
    plt.plot(n_array,C_array,'go')
    plt.savefig('BondACF%s.pdf' % (name))
    return None
```

``` {.sourceCode .python}
def calc_bondacf():
    """calculates bond acf"""
    psffile = "poly.psf"
    traj = "traj.dcd"
    u = Universe(psffile, traj)
    Nbonds = len(u.residues[0])-1
    Nres = len(u.residues)
    print "Nres = %r" % Nres
    print "Nbonds = %r" % Nbonds
    bonds = np.array((Nbonds,3))
    C = np.zeros(Nbonds)
    k = 0
    for ts in u.trajectory[0:-1:1]:
        print "time = %r" % ts.frame
        for res in u.residues:
            bonds = get_bondlist_coords(res)
            k+=1
            for ui in range(0,Nbonds):
                C[ui] += np.dot(bonds[0],bonds[ui])
    C /= float(k)
    ui_array = np.arange(Nbonds)
    save_plot_bondacf(ui_array,C,"bondacf")
    return None
```

Results:
--------

``` {.sourceCode .python}
calc_bondacf()
```

![image](./images/output_6_1.png)

As we can see at \$n=11\$ our green dots start being different than the
red curve(the fitting curve), therefore the persistance length : \$l\_p
= n\*l\_0 = 11\*1.3 A\$.

Accelerating Python
===================

date

:   2015-4-14 22:05

tags

:   Python, MDAnalysis, Perfomance, Analysis

category

:   Python

slug

:   accelerating-python

summary

:   How to accelerate Python code?

Python is great, Python is easy to learn, easy to write in, but
sometimes we need our code to run fast. This is where pure Python falls
short. Just as many other languages with dynamical variable typing - it
is very slow. For example consider this code snippet:

``` {.sourceCode .python}
a = 1
for i in range(10000):
    a = i
```

For every loop Python analyzes the type of i, sets a new variable a of
i. This is where such languages as C or Fortran come handy, they are
arguably the fastest languages in the game today. Luckily there are
several ways of improving performance of our Python code:

1.  Numpy
2.  Cython
3.  ff2
4.  Numba

Numpy - [numpy]\_ - is an extension to the Python programming language,
adding support for large, multi-dimensional arrays and matrices, along
with a large library of high-level mathematical functions to operate on
these arrays. Basically, people tried to make Python a scientific
language, to do that you need to be Matlab-like, i.e focus on arrays as
your main structure in the code. That was done in Numpy. It is a key
library to all scientific programming on Python.

[cython]\_ - is an optimising static compiler for both the Python
programming language and the extended Cython programming language (based
on Pyrex). It makes writing C extensions for Python as easy as Python
itself. In other words you find something very slow in your code(a
bottleneck) write a something that looks like Python and C at the same
time, compile it and use it in your code. This time your bottleneck
will(supposedly) run very fast.

f2py ([fortran]\_) - is a project which aims to provide a connection
between Python and Fortran languages. The idea is similar to Cython, but
the connection is done with Fortran.

Finally, if you are a lazy person just like me, you may want to try
[numba]\_. If you recally the example in the begging of this page where
Python was dynamicaly setting type int to variable a. You find slow
parts in your code, put them into function, add numba directive @jit and
run your program. Numba takes care of the rest. Sounds good eh? Lets
have a closer look on it:

The most frequent code snippet used to demonstrate numba is this:

``` {.sourceCode .python}
import numpy as np
X = np.random.random((1000, 3))

def pairwise_python(X):
    M = X.shape[0]
    N = X.shape[1]
    D = np.empty((M, M), dtype=np.float)
    for i in range(M):
        for j in range(M):
            d = 0.0
            for k in range(N):
                tmp = X[i, k] - X[j, k]
                d += tmp \* tmp
            D[i, j] = np.sqrt(d)
    return D
%timeit pairwise_python(X)
```

``` {.sourceCode .python}
1 loops, best of 3: 13.4 s per loop
```

Now if we add a @autojit Numba directive to the top:

``` {.sourceCode .python}
from numba import double
from numba.decorators import jit, autojit

pairwise_numba = autojit(pairwise_python)

%timeit pairwise_numba(X)
```

``` {.sourceCode .python}
1 loops, best of 3: 9.12 ms per loop
```

Impressive isn't it? Now lets take an interesting problem for Molecular
Simulation and write a program using Numba library. Calculating g(r) -
Radial Distribution Function [rdf]\_ .

![image](./images/rdf_atoms.jpeg)

![image](./images/rdf.png)

In order to analyze the structure of a solid or fluid one often looks at
the radial pair distribution function (RDF)

$$g(r) = \frac{V}{N^{2}}\left\langle \sum_{i=1}^{N}\sum_{j\neq i}\delta(\vec{r} - \vec{r}_{ij})\right\rangle \quad\text{with}\vec{r}_{ij}:= \vec{r}_{j} - \vec{r}_{i}$$$

What this really means is that \$g(r)dr\$ is the number of atoms at
distance \$r\$ from one arbitrary atom in a thin shell of thickness
\$dr\$, relative to the number at the same distance in an ideal gas at
the same (constant!) density

So lets write the algorithm for the program:

1.  loop over all atoms
2.  for ever atoms loop over the rest
3.  get the distance(consider pbc) histogramm it
4.  normalize the histogramm so the r-\>inf it -\> 1.0

``` {.sourceCode .python}
# Purpose: Calculate radial distribution function  using Python and Numba library
# Author:  Triandafilidi Vasiliy , MSc student at CHBE UBC, Vancouver
# e-mail:  vtriandafilidi(at)chbe(dot)ubc(dot)ca
# Syntax:  python  python_numba_rdf.py
# Requires: poly.psf poly.pdb, numba library

# Theory:
# http:\//en.wikipedia.org/wiki/Radial_distribution_function
#
#
# Copyright (c) 2014 Vasiliy Triandafilidi
# Released under the GNU Public Licence, v2 or any higher version

from numba import jit, autojit,njit
import matplotlib.pyplot as plt
import math
from MDAnalysis import \*
import numpy as np

@jit('f8(f8)',nopython=True)
def CUB(x):
    return x\*\*3.


#loop over all atoms
#for ever atoms loop over the rest
#get the distance(consider pbc) histogramm it
@jit('void(float32[:,:],float32[:],float32,float32,float32)',nopython=True)
def pairwise_python(X,g,L,smax,db):
    M = X.shape[0]
    N = X.shape[1]
    nbins = int(smax/db)
    for i in range(M-1):
        # print " atom " , i
        for j in range(i+1,M):
            d = 0.0
            for k in range(N):
                tmp = X[i, k] - X[j, k]
                tmp = numbatrunc(tmp,L)
                d += tmp \* tmp
            d = np.sqrt(d)
            if (d < smax):
                g[int(d/db)] += 2.0


#normalize the histogramm so the r->inf it -> 1.0
@jit('void(float32[:],float32,float32,int32)',nopython=True)
def normalise(A,L,db,N):
    n = A.shape[0]
    # pairs = float(N)\*(float(N)-1.0)/float(2)
    pairs = float(N)\*(float(N))
    factor = (4./3.)\*np.pi\*pairs/CUB(L)
    density = N/CUB(L)
    for i in range(n):
        A[i] /= factor\*(CUB(i+1)-CUB(i))\*CUB(db)


u = Universe("poly.psf","poly.pdb")
a = u.selectAtoms("all")
aa = a.positions
box = u.universe.dimensions[:3]
L = box[0]
smax = 10.0
db = 0.1
nbins = int(smax/db)
D = np.zeros(nbins, dtype=np.float32)

bins = np.linspace(0,smax,nbins)

pairwise_python(aa,D,L,smax,db,len(aa))
normalise(D,L,db)
```

Must Know Bash Commands
=======================

date

:   2015-4-14 23:45

tags

:   Bash, Software

category

:   Bash

slug

:   must-know-bash-commands

summary

:   What are the must know Bash commands?

What are tricky bash commands that I consider useful:

Basic ls, rm, grep commands
---------------------------

``` {.sourceCode .bash}
ls file # does the file exist?
ls -l file # info about file
ls -lt  #  list files in time order with info
ls -ltr  #  list files in reverse time order with info
ls -a # list files including hidden files
ls - R $ show dirs and subdirs

rm !(u|p) # delete everything but
```

Creating a symbolic link:

``` {.sourceCode .bash}
ln -s original linkname
```

Grepping:

``` {.sourceCode .bash}
ls | grep something # prints something, that matches something
less file1 | grep something # looks for something in the file
grep "hi there" file1 # look for hi there in the file1
ls | grep something | xargs rm # removes everything that matches something in the directory
```

Grepping `str1` or/and `str2`:

``` {.sourceCode .bash}
egrep -i "str1|str2" file # str1 or str2
egrep -i "str1.\*str2" file # str1 and str2
```

How to find files?
------------------

Here are a few ways to use find:

``` {.sourceCode .bash}
$ find ./ -name 'name.\*'
```

./

``` {.sourceCode .bash}
Start searching from the current directory (i.e ./ directory)
```

-name

``` {.sourceCode .bash}
Given search text is the filename rather than any other attribute of a file
```

'name.\*'

``` {.sourceCode .bash}
Search text that we have entered. Always enclose the filename in single quotes.. why to do this is complex.. so simply do so.
```

``` {.sourceCode .bash}
$ find /home/david -name 'index\*'
$ find /home/david -iname 'index\*'
```

The 1st command would find files having the letters index as the
beginning of the file name. The search would be started in the directory
/home/david and carry on within that directory and its subdirectories
only. The 2nd command would search for the same, but the case of the
filename wouldn't be considered. So all files starting with any
combination of letters in upper and lower case such as INDEX or indEX or
index would be returned.

Parsing through text files using sed/awk
----------------------------------------

Sed:

Replace `foo` with `bar`:

``` {.sourceCode .bash}
sed 's/foo/bar/'
```

Replace `Word1` with `Word2`, `-n` - gets rid of unnecessary stuff

``` {.sourceCode .bash}
sed -n '/Word1/Word2/' fromfile.txt > newfile.txt
```

Deleting lines:

``` {.sourceCode .bash}
sed -i '/^\s*$/d'  fromfile.txt # delete empty lines fromfile.txt (modifies the file)
sed -i '1d' filewithfirstline.txt # deletes first line of a file
sed -i '1i\\' filewithfirstline.txt # adds empty first line to file
```

``` {.sourceCode .bash}
sed -e '/^$/d' $filename
# The -e option causes the next string to be interpreted as an editing instruction.
#  (If passing only a single instruction to sed, the "-e" is optional.)
#  The "strong" quotes ('') protect the RE characters in the instruction
#+ from reinterpretation as special characters by the body of the script.
# (This reserves RE expansion of the instruction for sed.)
#
# Operates on the text contained in file $filename.


8d  #Delete 8th line of input.
/^$/d   #Delete all blank lines.
1,/^$/d #Delete from beginning of input up to, and including first blank line.

/Jones/p  #  Print only lines containing "Jones" (with -n option).
s/Windows/Linux/   # Substitute "Linux" for first instance of "Windows" found in each input line.
s/BSOD/stability/g  #Substitute "stability" for every instance of "BSOD" found in each input line.

s/ \*$// #Delete all spaces at the end of every line.
s/00\*/0/g   #Compress all consecutive sequences of zeroes into a single zero.

echo "Working on it." | sed -e '1i How far are you along?'  #Prints "How far are you along?" as first line, "Working on it" as second.
5i 'Linux is great.' file.txt   #Inserts 'Linux is great.' at line 5 of the file file.txt.
/GUI/d  #Delete all lines containing "GUI".
s/GUI//g    #Delete all instances of "GUI", leaving the remainder of each line intact.
```

Aliasing
--------

The alias command makes it possible to launch any command or group of
commands (inclusive of any options, arguments and redirection) by
entering a pre-set string (i.e., sequence of characters). In other words
you find some command that you use a lot, say go to certain directory,
or ssh to certain server give it a nickname (alias) and use it.

For example I know that I go to certain folder a lot, it has all my
libraries in it -
/Dropbox/Lammps\_simulation/my\_git\_repo/polymer\_simulation/CreateMelt
So I just add the following line to \~/.bashrc (\~/bash\_profile),
source it source \~/.bashrc and use it.

``` {.sourceCode .bash}
alias createmelt='cd ~/Dropbox/Lammps_simulation/my_git_repo/polymer_simulation/CreateMelt'
```

For now on, whenever I need to go to the
/Dropbox/Lammps\_simulation/my\_git\_repo/polymer\_simulation/CreateMelt
directory I use

``` {.sourceCode .bash}
$ ~/blog @ Vasiliys-MacBook-Pro (bazilevs)
$ => pwd
/Users/bazilevs/blog

$ ~/blog @ Vasiliys-MacBook-Pro (bazilevs)
$ => createmelt

$ ~/Dropbox/Lammps_simulation/my_git_repo/polymer_simulation/CreateMelt @ Vasiliys-MacBook-Pro (bazilevs)

$ => pwd
    /Users/bazilevs/Dropbox/Lammps_simulation/my_git_repo/polymer_simulation/CreateMelt


source
```

``` {.sourceCode .bash}
# very handy tool to go any number of directories up
up(){
  local d=""
  limit=$1
  for ((i=1 ; i <= limit ; i++))
    do
      d=$d/..
    done
  d=$(echo $d | sed 's/^\///')
  if [ -z "$d" ]; then
    d=..
  fi
  cd $d
}

# very handy tool to extract files
extract () {
    if [ -f $1 ] ; then
      case $1 in
        \*.tar.bz2)   tar xjf $1     ;;
        \*.tar.gz)    tar xzf $1     ;;
        \*.bz2)       bunzip2 $1     ;;
        \*.rar)       unrar e $1     ;;
        \*.gz)        gunzip $1      ;;
        \*.tar)       tar xf $1      ;;
        \*.tbz2)      tar xjf $1     ;;
        \*.tgz)       tar xzf $1     ;;
        \*.zip)       unzip $1       ;;
        \*.Z)         uncompress $1  ;;
        \*.7z)        7z x $1        ;;
        \*)     echo "'$1' cannot be extracted via extract()" ;;
         esac
     else
         echo "'$1' is not a valid file"
     fi
}
```

Github basic commands:
----------------------

I assume one does have a working account, then everything is pretty
straightforward:

``` {.sourceCode .bash}
#initialize this directory to be github directory
git init .
# when you have files to push
git add .
# adding information on the commit
git commit -m "i added a lot of stuff"
git push origin master
```

When you are cloning a directory that it gets initialized automatically.

Static Structure Factor
=======================

date

:   2015-4-20 17:25

tags

:   MDAnalysis, Python, Analysis

category

:   MDAnalysis

slug

:   static-structure-factor

summary

:   How to calculate static structure factor?

### Applications. Why do we need it?

Molecular Dynamics (MD) simulations provides is with a great tool that
can analyze behavior on atomic level. It predicts motion of atoms on the
scale not reachable to experimental techniques. A natural question
arises how does one builds a bridge between MD simulations and
experimental results. One way of doing that would be to obtain
integrated quantities such Pressure, Temperature or Static Structure
Factor(SSF), which can be directly seen from the experiment. For example
SSF is proportional to intensity of the diffracted light in the x-ray
diffraction experiment. Interested readers are encouraged to find more
about SF in the following
[presentation](http://www.lehigh.edu/imi/teched/AtModel/Lecture_5_Micoulaut_Atomistics_Glass_Course.pdf),
and this paper
[kob\_et\_al](http://journals.aps.org/prb/abstract/10.1103/PhysRevB.60.3169).

![image](./images/sq/Sq_diffract.jpg)

### Mathematical background

To be able to understand certain physical phenomena one needs to be
familiar with its mathematical background. For example Static Structure
Factor is impossible to understand without the prior knowledge of
Fourier Transform(FT).

Let us start from a definition of Fourier Series.

> a Fourier series - is a way to represent a wave-like function as the
> sum of simple sine waves

> -- wikipedia.org

In other words: for every function \$f(x)\$ (mathematically good enough)
coefficients (\$a\_n\$, \$b\_n\$, \$\\omega\_n\$) can be found which
will fit this function.

\$\$f(x) = \\Sigma (a\_n cos(\\omega\_n x) + b\_n sin(\\omega\_n x))
\$\$

These: \$a\_n\$ and \$b\_n\$ are called Fourier coefficients, \$cos
(\\omega\_n x)\$, \$sin(\\omega\_nx)\$ are called Fourier harmonics.

If we rewrite our Fourier Transform using complex numbers it will look
like this: \$\$f(x) = \\Sigma c\_n e\^{-i \\omega\_n x}\$\$

In many physical applications only absolute value squared plays role,
because it represents intensity of physical value, and experiments in
physical world can measure only intensity, rather than fields. For
example Static Structure Factor, which is to be discussed in further
detail below. Therefore value which we are interested in is:

\$\$ I = \\Sigma \\mid c\_n \\mid\^2 = \\Sigma (\\mid a\_n \\mid\^2 +
\\mid b\_n \\mid\^2)\$\$

For better understanding let us consider following example:

1.  Fourier series of a simple function \$f(x) = cos(x)\$ is the
    function itself. Therefore: \$ a\_1 = 1 \$, \$a\_i = 0\$ for every
    \$ i \\neq 1 \$, \$b\_i = 0\$ for every \$i\$. So an infinite curve
    can be represented by a single value.

To read about Fourier Series in greater detail interested reader is
encouraged to read the following sources :
[Fourier\_expalained](http://math.stackexchange.com/questions/1002/fourier-transform-for-dummies),
[wikipedia](http://en.wikipedia.org/wiki/Fourier_series)

Fourier Transform is very based on Fourier Series
[Fourier\_transform](http://en.wikipedia.org/wiki/Fourier_transform).
For every function in the regular space we find a number in the
reciprocal space. In other words we define an operator which maps
functions onto numbers. Therefore we analyze function by their image,
which we call spectrum. For example in the figure below we have a
\$cos\$ function of certain period, this period corresponds to spectrum
of the function in reciprocal space.

![image](./images/sq/fourier.jpg)

Note: Infinite curve after Fourier Transform becomes a single value,
whereas a peak becomes and infinite curve. This has very deep and
fundamental consequences and is directly related to uncertainty
principal

Interested reader might already noticed that the bigger the period is by
x, the smaller is the \$k\$ value - the wave vector .

### Theoretical background

![image](./images/sq/RdfSqExplained.jpg)

Let us look at the Fig. 2.. Visually we can identify periodic structure
on the left side and a random structure on the right side. How can one
quantify this order?

To be able to quantify this order may use Radial Distribution
Function(RDF)
[RDF](http://en.wikipedia.org/wiki/Radial_distribution_function) . By
now we will define RDF as an average number of atoms on the distance
\$r\$ from a given atom, averaged by all atoms. Later we will define RDF
in more rigorous way.

We see a clear periodicity on the plot, which corresponds to the periodicity of the structure. Although Radial Distribution Function seems to provide us with important information about system structure it is still not very convenient to use. Things get even more complicated when we have to periodic structures (structure within other structure) like in the Fig. 3.

:   So we are not there yet. We want to be able to identify a periodic
    structure by just a number, not a function.

If we recall our Fourier series whenever we had something periodic in
distance space we will have a peak in the reciprocal space. And that is
what we want - an easy way to track positions of atoms!

Now, if we have a structure with two characteristic distances we will be
represented by two peaks in the reciprocal space.

![image](./images/sq/Sq.jpg)

Now lets formulate statements above in a mathematically sound way:

If we have a system of atoms with positions \$ \\mathbf{r}\_{j} \$, then

Radial distribution function \$g(r)\$:

\$\$g(r) = \\frac{V}{N\^{2}}\\left\\langle
\\sum\_{i=1}\^{N}\\sum\_{j\\neq i}\\delta(\\vec{r} -
\\vec{r}\_{ij})\\right\\rangle \\quad\\text{with} \\vec{r}\_{ij}:=
\\vec{r}\_{j} - \\vec{r}\_{i} \$\$

, the static structure factor is defined as:

\$\$ S(\\mathbf{q}) = \\frac{1}{N} \\left | \\sum\_{j=1}\^{N}
\\mathrm{e}\^{-i \\mathbf{q} \\mathbf{r}\_{j}} \\right | \^2\$\$

Which is an absolute value of Fourier coefficient squared. It can
equally expressed the following way:

\$\$ S(\\mathbf{q}) = 1 + \\frac{1}{N} \\left \\langle \\int\_V
\\mathrm{d} \\mathbf{r} \\, \\mathrm{e}\^{-i \\mathbf{q} \\mathbf{r}}
\\sum\_{i \\neq j} \\delta \\left [ \\mathbf{r} - (\\mathbf{r}\_i -
\\mathbf{r}\_j) \\right ] \\right \\rangle \$\$

Which is the definition we will work with.

### Implementation

Now several points need to be clarified:

To implement the algorithm above we need to figure out how to :

> 1.  to evaluate integral
> 2.  to deal with delta function

Evaluating integral with exponent would be performing a Fourier
transform, therefore we can use tools available for that : FFT - fast
fourier transform.

Delta function will be considered by binning and histograming our atomic
positions \$\\mathbf{r}\_{j}\$, which will be demonstrated on 2D example
for convenience.

![image](./images/sq/histogram.jpg)

To start with lets import everything that we will need for our program:

``` {.sourceCode .python}
import numpy as np
from MDAnalysis import \*
from read_parameters import read_traj_vmd
import os
import save_plots
from numpy.fft import fftn, fftshift
import scipy
from scipy.integrate import quad
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
```

Lets define some necessary variables and bin the data:

``` {.sourceCode .python}
u = Universe(psffile+'.psf', args.traj)
Ndiv = 201
# create arrays of positions, get the box dimenstions
X = u.atoms.positions
box = u.trajectory.ts.dimensions[:-3]
length_x = box[-1]  # be careful here
x = np.linspace(-length_x, length_x, Ndiv+1, endpoint=True)
# binning and histogramming
f, edges = np.histogramdd(X, bins=(Ndiv, Ndiv, Ndiv))
delta = x[1]-x[0]
```

Ok, now we are all set to do Fourier Transform and "go" to reciprocal
space

``` {.sourceCode .python}
ftk = (fftshift(fftn(fftshift(f))\*delta))
sk = np.abs(ftk\*\*2) / float(Natoms)
# basis in reciporal space
omega = 2\*np.pi\*np.arange(Ndiv-1) / (length_x)
omega -= omega[int(Ndiv/2)-1]
```

We are almost all set, the only thing is that we need to radially
average our data, since we are interested only in the \$|q|\$

``` {.sourceCode .python}
C = norm_sq(sk, k1, k2, k3, Ndiv, kmax)
```

``` {.sourceCode .python}
def norm_sq(sk, k1, k2, k3, Ndiv, kmax):
    """
    calculates normk = norm of each vector in grid=|k1,k2,k3|
    bins in, calculating average sq of each bin
    output: C[Nbins,3] = binindex, kval = normk, sq
    """
    normk = np.sqrt(k1\*k1 + k2\*k2 + k3\*k3)
    # array to histogram - dk,kmax,Nbins
    Nbins = int(1.5\*Ndiv)
    dk = kmax/float(Nbins)
    C = np.ones((Nbins+1, 3))
    for i in range(Ndiv-1):
        for j in range(Ndiv-1):
            for k in range(Ndiv-1):
                kval = normk[i, j, k]
                bindex = int(kval/dk)
                C[bindex, 0] += 1
                C[bindex, 1] += kval
                C[bindex, 2] += sk[i, j, k]
    C[:,2] /= C[:,0]
    C[:,1] /= C[:,0]
    return C
```

Special thanks for Amanda Parker.
